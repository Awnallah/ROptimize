{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_validate, train_test_split, ShuffleSplit, learning_curve, validation_curve\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, balanced_accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, normalize, MinMaxScaler, LabelEncoder\n",
    "import itertools\n",
    "import timeit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import dill\n",
    "# # # from dill.settings import settings\n",
    "# dill.dump_session('wilt-nt.db')\n",
    "# # dill.load('done-seiwilt.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# col_names = ['F1', 'F2', 'F3', 'class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_wilt = pd.read_csv('wilt_tr_bal.csv' )\n",
    "\n",
    "print(\"Data has\",len(df_wilt),\"rows and\", len(df_wilt.columns),\"columns.\")\n",
    "if df_wilt.isnull().values.any():\n",
    "    print(\"Data missing\")\n",
    "#df_bankn.head()\n",
    "df_wilt.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_wilt_test = pd.read_csv('wilt_test.csv' )\n",
    "\n",
    "print(\"Data has\",len(df_wilt_test),\"rows and\", len(df_wilt_test.columns),\"columns.\")\n",
    "if df_wilt.isnull().values.any():\n",
    "    print(\"Warning: Missing Data\")\n",
    "#df_bankn.head()\n",
    "df_wilt.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sns.pairplot(df_wilt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.title(\"Wilt Data - Features Correlation\")\n",
    "# plt.xlabel('Mean Red')\n",
    "# plt.ylabel('Mean Green')\n",
    "# plt.scatter(df_wilt['Mean_Red'], df_wilt['Mean_Green'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_wilt['Mean_Red'].corr(df_wilt['Mean_Green'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.title(\"Counts of Wilt Data Labels\")\n",
    "# sns.countplot(df_wilt['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_wilt['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn import preprocessing\n",
    "# le = preprocessing.LabelEncoder()\n",
    "# le.fit(df_clean['y'])\n",
    "# #le.transform(df_clean['y'])\n",
    "# df_labels = df_wilt[['seismoacoustic','ghazard']].apply(LabelEncoder().fit_transform)\n",
    "#df_labels.describe()\n",
    "\n",
    "\n",
    "encoder = LabelEncoder().fit(df_wilt['class'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df_wilt['class'] = encoder.transform(df_wilt['class'])\n",
    "df_wilt_test['class'] = encoder.transform(df_wilt_test['class'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# names.insert(0, names.pop(names.index('y')))\n",
    "# df_num = df_clean[names[1:]]\n",
    "# x_scaled = min_max_scaler.fit_transform(df_num)\n",
    "col_names = df_wilt.columns\n",
    "print(col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scalar = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_scaled = pd.DataFrame(x_scaled, columns=names[1:])\n",
    "# df_scaled.head()\n",
    "# rem_names = ['genergy', 'gpuls', 'gdenergy',\n",
    "#        'gdpuls', 'nbumps', 'nbumps2', 'nbumps3', 'nbumps4',\n",
    "#        'nbumps5', 'nbumps6', 'nbumps7', 'nbumps89', 'energy', 'maxenergy',\n",
    "#        'class']\n",
    "\n",
    "\n",
    "scalar.fit(df_wilt[col_names[1:]])\n",
    "\n",
    "x_scaled = scalar.transform(df_wilt[col_names[1:]])\n",
    "x_scaled_test = scalar.transform(df_wilt_test[col_names[1:]])\n",
    "\n",
    "# df_sc = pd.DataFrame(x_scaled, columns=col_names[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tr_data():\n",
    "\n",
    "\n",
    "    x = np.array(x_scaled)\n",
    "    y = np.array(df_wilt.values[:,0]).astype('int')\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def get_test_data():\n",
    "\n",
    "\n",
    "    x = np.array(x_scaled_test)\n",
    "    y = np.array(df_wilt_test.values[:,0]).astype('int')\n",
    "\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Not splitting - this file is only for training\n",
    "X_train, y_train = get_tr_data()\n",
    "X_test, y_test = get_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_clean.sort_index(axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sns.countplot(x='class',data=df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.bincount(y_train), np.bincount(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sns.countplot(df_wilt['class'])\n",
    "# X_train, X_test, y_train, y_test = train_test_split(np.array(xBk),np.array(yBk), test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ros = RandomOverSampler(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_train , y_train = ros.fit_resample( X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.countplot(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling done only to training data. Testing data is still imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sns.countplot(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have successfully loaded and processed both datasets. We are ready to start the ML!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### helper funcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#src: sklearn\n",
    "def pllc(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 10)):\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"F1\")\n",
    "    \n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=-1, train_sizes=train_sizes, scoring='balanced_accuracy')\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    \n",
    "    results ={'sizes':train_sizes,'tr_scores':train_scores_mean, 'val_scores': test_scores_mean, 'title':title}\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"g\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"r\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return plt, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "def tune_hp(estimator, X_train, y_train, title, param_name,param_range, xlabel,xvals=None, cv=5):\n",
    "\n",
    "    \n",
    "            \n",
    "            \n",
    "    train_scores, val_scores = validation_curve(estimator, X_train, y_train, param_name, \n",
    "                                                 param_range, cv=cv, n_jobs=-1, scoring='accuracy')\n",
    "    \n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    #train_scores_std = np.std(train_scores, axis=1)\n",
    "    val_scores_mean = np.mean(val_scores, axis=1)\n",
    "    #test_scores_std = np.std(test_scores, axis=1)\n",
    "    \n",
    "    if xvals is not None:\n",
    "        param_range=xvals\n",
    "            \n",
    "    plt.grid(True)  \n",
    "    plt.plot(param_range, train_scores_mean, 'o-', color = 'g', label='Train Score')\n",
    "    plt.plot(param_range, val_scores_mean, 'o-', color='r', label='Validation Score')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel(xlabel)\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.legend(loc='best')\n",
    "#     plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# ML- NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn_test = mlrose.NeuralNetwork(activation ='relu', \n",
    "                                 algorithm ='gradient_descent',\n",
    "                                 max_iters = 3000, bias = True, is_classifier = True, \n",
    "                                 learning_rate = .0001, early_stopping = True, \n",
    "                                 max_attempts = 10, curve=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(solver='sgd', random_state=1, verbose=10, activation='relu'\n",
    "                    , learning_rate_init=0.01 ,)\n",
    "\n",
    "\n",
    "tune_hp(estimator=nn_test, X_train= X_train, y_train=y_train, title=\"NN Hypertunning No. nodes in hidden layer -Wilt Data\",\n",
    "        param_name='hidden_layer_sizes',param_range=[[10],[20],[40],[60],[80]],\n",
    "        xlabel=\"No. nodes in hidden layer\", xvals=None , cv=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# param_grid_nn = {'learning_rate_init':[0.01,.001, .1]}\n",
    "# mlp1 = MLPClassifier(solver='adam',random_state=1, verbose=0,learning_rate_init=.01 , hidden_layer_sizes=(80,), activation='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GSmlp = GridSearchCV(estimator = mlp1, param_grid=param_grid_nn, cv=5, scoring='f1', n_jobs=-1)\n",
    "# GSmlp.fit(X_train, y_train)\n",
    "# learning_rate_init =GSmlp.best_params_['learning_rate_init']\n",
    "# print(\"Tree Grid Search chosen parameters: \")\n",
    "# print(GSmlp.best_params_)\n",
    "# mlp1.fit(X_train, y_train)\n",
    "# print(mlp1.loss_curve_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# title = \"Learning Curve NN- Wilt Data\"\n",
    "# # Cross validation with 100 iterations to get smoother mean test and train\n",
    "# # score curves, each time with 20% data randomly selected as a validation set.\n",
    "# cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=1)\n",
    "\n",
    "# # estimator =  MLPClassifier(solver='adam',random_state=1, verbose=10, hidden_layer_sizes=(50,300,),\n",
    "# #                           learning_rate_init= 0.01, activation= 'relu')\n",
    "# _ , NNLC_results = pllc(mlp1, title, X_train, y_train, ylim=None, cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# NNLC_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final section for neural network will plot the loss curve for each dataset over the iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# iters = np.arange(1,len(mlp1.loss_curve_)+1).astype(int)\n",
    "# print(iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# plt.figure()\n",
    "# plt.title(\"NN- Loss Curve - Wilt Data\")\n",
    "# plt.xlabel(\"Number of Iterations\")\n",
    "# plt.ylabel(\"Log Loss\")\n",
    "# plt.plot(iters, mlp1.loss_curve_, 'o-', markersize=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# comparison plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# #results = [DTLC_results, NNLC_results, GBDTLC_results, SVM_results, KNN_results]\n",
    "\n",
    "# def plot_LRs(sizes,DTLC_results, NNLC_results, GBDTLC_results, SVM_results, KNN_results, title,scr):\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.title(title)\n",
    "#     plt.xlabel(\"Training Examples\")\n",
    "#     plt.ylabel(\"Model F1 Score\")\n",
    "#     plt.plot(sizes, DTLC_results[scr], '-', color=\"r\", label=\"DT\")\n",
    "#     plt.plot(sizes, NNLC_results[scr] , '-', color=\"g\", label=\"NN\")\n",
    "#     plt.plot(sizes, GBDTLC_results[scr] , '-', color=\"b\", label=\"Grad-Bosted\")\n",
    "#     plt.plot(sizes, SVM_results[scr] , '-', color=\"k\", label=\"SVM\")\n",
    "#     plt.plot(sizes, KNN_results[scr] , '-', color=\"y\", label=\"KNN\")\n",
    "#     plt.legend(loc=\"best\")\n",
    "#     #plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot_LRs(DTLC_results['sizes'],DTLC_results, NNLC_results, GBDTLC_results, SVM_results, KNN_results, \"Validation Learning Rates - Wilt Data\",'val_scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot_LRs(DTLC_results['sizes'],DTLC_results, NNLC_results, GBDTLC_results, SVM_results, KNN_results, \"Validation Learning Rates - Wilt Data\",'val_scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot_LRs(DTLC_results['sizes'],DTLC_results, NNLC_results, GBDTLC_results, SVM_results, KNN_results, \"Training Learning Rates - Wilt Data\",'tr_scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot_LRs(DTLC_results['sizes'],DTLC_results, NNLC_results, GBDTLC_results, SVM_results, KNN_results, \"Training Learning Rates - Wilt Data\",'tr_scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot_LRs(DTLC_results['sizes'],DTLC_results, NNLC_results, GBDTLC_results, SVM_results, KNN_results, \"Validation Learning Rates - Wilt Data\",'val_scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# results = [DTLC_results, NNLC_results, GBDTLC_results, SVM_results, KNN_results]\n",
    "\n",
    "# print(results)\n",
    "# def plot_LRs(n,DTLC_results, NNLC_results, GBDTLC_results, SVM_results, KNN_results, title):\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.title(\"Model Learning Rates: \" + title)\n",
    "#     plt.xlabel(\"Training Examples\")\n",
    "#     plt.ylabel(\"F1_macro\")\n",
    "#     plt.plot(n, NNlearn, '-', color=\"b\", label=\"Neural Network\")\n",
    "#     plt.plot(n, SMVlearn, '-', color=\"r\", label=\"SVM\")\n",
    "#     plt.plot(n, kNNlearn, '-', color=\"g\", label=\"kNN\")\n",
    "#     plt.plot(n, DTlearn, '-', color=\"m\", label=\"Decision Tree\")\n",
    "#     plt.plot(n, BTlearn, '-', color=\"k\", label=\"Boosted Tree\")\n",
    "#     plt.legend(loc=\"best\")\n",
    "#     plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testing_func(clf,X_train, X_test, y_train, y_test, title):\n",
    "    \n",
    "    print(clf)\n",
    "    \n",
    "    start_time = timeit.default_timer()\n",
    "    clf.fit(X_train, y_train)\n",
    "    curve = clf.fitness_curve\n",
    "    end_time = timeit.default_timer()\n",
    "    training_time = end_time - start_time\n",
    "    \n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    \n",
    "    start_time = timeit.default_timer()    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    end_time = timeit.default_timer()\n",
    "    pred_time = end_time - start_time\n",
    "    \n",
    "    \n",
    "    rf1 = f1_score(y_train,y_pred_train)\n",
    "    raccuracy = accuracy_score(y_train,y_pred_train)\n",
    "    rbal_accuracy = balanced_accuracy_score(y_train,y_pred_train)\n",
    "    rprecision = precision_score(y_train,y_pred_train)\n",
    "    rrecall = recall_score(y_train,y_pred_train)\n",
    "#     cm = confusion_matrix(y_train,y_pred_train )\n",
    "    \n",
    "\n",
    "    f1 = f1_score(y_test,y_pred)\n",
    "    accuracy = accuracy_score(y_test,y_pred)\n",
    "    bal_accuracy = balanced_accuracy_score(y_test,y_pred)\n",
    "    precision = precision_score(y_test,y_pred)\n",
    "    recall = recall_score(y_test,y_pred)\n",
    "    cm = confusion_matrix(y_test,y_pred )\n",
    "    \n",
    "    df_cm = pd.DataFrame(cm, index= ['n', 'w'] , columns= ['n' , 'w'])\n",
    "\n",
    "    plt.plot(-curve)\n",
    "    plt.title(title + \" Loss Curve\")\n",
    "    plt.xlabel(\"iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "    print(\"*********Training data***************\")\n",
    "    print(\"F1 Score:  \"+\"{:.2f}\".format(rf1))\n",
    "    print(\"Accuracy:  \"+\"{:.2f}\".format(raccuracy))\n",
    "    print(\"Balanced Accuracy:  \"+\"{:.2f}\".format(rbal_accuracy))\n",
    "    print(\"Precision: \"+\"{:.2f}\".format(rprecision))\n",
    "    print(\"Recall:  \"+\"{:.2f}\".format(rrecall))\n",
    "\n",
    "    print(\"*********Testing***************\")\n",
    "    print(\"Model Training Time (s):   \"+\"{:.5f}\".format(training_time))\n",
    "    print(\"Model Prediction Time (s): \"+\"{:.5f}\\n\".format(pred_time))\n",
    "    print(\"F1 Score:  \"+\"{:.2f}\".format(f1))\n",
    "    print(\"Accuracy:  \"+\"{:.2f}\".format(accuracy))\n",
    "    print(\"Balanced Accuracy:  \"+\"{:.2f}\".format(bal_accuracy))\n",
    "    print(\"Precision: \"+\"{:.2f}\".format(precision))\n",
    "    print(\"Recall:  \"+\"{:.2f}\".format(recall))\n",
    "    print(\"Time per iteration: \" + \"{:.5f}\".format(training_time/curve.size))\n",
    "\n",
    "    \n",
    "    sns.heatmap(df_cm,cmap=\"YlGnBu\", annot=True, fmt=\"d\")\n",
    "    plt.title(title + \" Confusion Matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# f_DT  = DecisionTreeClassifier(criterion='gini',max_depth=5, min_samples_leaf= 1, random_state=1)\n",
    "# f_nn = MLPClassifier(solver='adam',random_state=1, hidden_layer_sizes=(80,),\n",
    "#                           learning_rate_init= 0.01, activation= 'relu')\n",
    "# f_GBC = GradientBoostingClassifier(max_depth=4 , min_samples_leaf=1 , n_estimators=78,random_state=1,)\n",
    "# f_svm = SVC(random_state=1, kernel='rbf', C=15, gamma=0.2)\n",
    "# f_KNN = KNeighborsClassifier(n_jobs=-1, n_neighbors=1,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pipreqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pipreqs -print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testing_func(f_DT,X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# testing_func(f_nn,X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# testing_func(f_nn_new,X_train, X_test, y_train, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testing_func(f_svm,X_train_sc, X_test_sc, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# f_nn_new = MLPClassifier(solver='sgd',random_state=1, hidden_layer_sizes=(80,),\n",
    "#                           learning_rate_init= 0.01, activation= 'relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# import mlrose #import the module here, so that it can be reloaded.\n",
    "# importlib.reload(mlrose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mlroseh import mlrose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn_model_gd.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn_model1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn_model_sa.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.plot(nn_model2.predicted_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train_pred = nn_model_sa.predict(X_train)\n",
    "\n",
    "y_train_accuracy = balanced_accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "print(y_train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test_pred = nn_model_rhc.predict(X_test)\n",
    "accuracy_test = balanced_accuracy_score(y_test,y_test_pred)\n",
    "print(accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test_pred = nn_model_sa.predict(X_test)\n",
    "accuracy_test = balanced_accuracy_score(y_test,y_test_pred)\n",
    "print(accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(nn_model_sa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn_model_gd = mlrose.NeuralNetwork(hidden_nodes = [40], activation ='relu', \n",
    "                                 algorithm ='gradient_descent',\n",
    "                                 max_iters = 5000, bias = True, is_classifier = True, \n",
    "                                 learning_rate = .0001, early_stopping =True,\n",
    "                                 max_attempts = 10, curve=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testing_func(nn_model_gd,X_train, X_test, y_train, y_test, \"Gradient-Descent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn_model_rhc = mlrose.NeuralNetwork(hidden_nodes = [40], activation ='relu', \n",
    "                                 algorithm ='random_hill_climb',\n",
    "                                 max_iters = 50000, bias = True, is_classifier = True, \n",
    "                                 learning_rate = 0.1, early_stopping = True, \n",
    "                                schedule=mlrose.ExpDecay(),\n",
    "                                 max_attempts = 100, curve=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testing_func(nn_model_rhc,X_train, X_test, y_train, y_test, \"RHC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn_model_sa = mlrose.NeuralNetwork(hidden_nodes = [40], activation ='relu', \n",
    "                                 algorithm ='simulated_annealing', schedule = mlrose.ExpDecay(init_temp=0.5, exp_const=0.005, min_temp=0.0001) ,\n",
    "                                 max_iters = 50000, bias = True, is_classifier = True, \n",
    "                                 learning_rate = 10, early_stopping = True, \n",
    "                                 max_attempts = 100, curve = True)#3000 temp init 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testing_func(nn_model_sa,X_train, X_test, y_train, y_test, \"Simulated Annealing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testing_func(nn_model_sa,X_train, X_test, y_train, y_test, \"Simulated Annealing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testing_func(nn_model_sa,X_train, X_test, y_train, y_test, \"Simulated Annealing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testing_func(nn_model_sa,X_train, X_test, y_train, y_test, \"Simulated Annealing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn_model_ga = mlrose.NeuralNetwork(hidden_nodes = [40], activation ='relu', \n",
    "                                 algorithm ='genetic_alg',pop_size=200,\n",
    "                                 max_iters = 500, bias = True, is_classifier = True, \n",
    "                                 learning_rate = .1, early_stopping = True,\n",
    "                                   mutation_prob=.1,\n",
    "                                 max_attempts = 100, curve=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testing_func(nn_model_ga,X_train, X_test, y_train, y_test, \"Genetic Algorithm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testing_func(nn_model_ga,X_train, X_test, y_train, y_test, \"Genetic Algorithm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testing_func(nn_model_ga,X_train, X_test, y_train, y_test, \"Genetic Algorithm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testing_func(nn_model_ga,X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testing_func(nn_model3,X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
